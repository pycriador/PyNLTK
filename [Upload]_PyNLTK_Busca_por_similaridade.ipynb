{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Upload] PyNLTK - Busca por similaridade",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPLaNQISGj0d7Pd1fOKYU13",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pycriador/PyNLTK/blob/main/%5BUpload%5D_PyNLTK_Busca_por_similaridade.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Projeto de Abril\n",
        "\n",
        "Um programa simples para encontrar similaridade em frases com base em um dicionário."
      ],
      "metadata": {
        "id": "MEHoH5F3r-jG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primeiro, vamos importar as bibliotecas necessárias:"
      ],
      "metadata": {
        "id": "h6S3TkP6sVXl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTf5iB-bFCAY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import unicodedata, re\n",
        "import json\n",
        "import os\n",
        "\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Em seguida, vamos importar as classes que vamos utilizar no projeto:"
      ],
      "metadata": {
        "id": "q0TQitwUscbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class check_similar():\n",
        "       \n",
        "    def normalize(self, palavra):\n",
        "        palavra = palavra.replace(',',' ')\n",
        "        palavra = palavra.replace('.',' ')\n",
        "        palavra = palavra.replace(';',' ')\n",
        "        palavra = palavra.replace(':',' ')\n",
        "        palavra = palavra.replace('-',' ')\n",
        "        nfkd = unicodedata.normalize('NFKD', palavra)\n",
        "        palavra = u\"\".join([c for c in nfkd if not unicodedata.combining(c)])\n",
        "        palavra = re.sub('[^a-zA-Z0-9 \\\\\\]', '', palavra)\n",
        "        palavra = palavra.upper()\n",
        "        return palavra\n",
        "    \n",
        "    def carregar_excel(self, xlsx, sheet=None):\n",
        "        xlsx = pd.ExcelFile(xlsx)\n",
        "        self.base = pd.read_excel(xlsx,sheet)\n",
        "        return self.base\n",
        "    \n",
        "    def criar_lista(self, coluna, normalizar=True, df=None):\n",
        "        if not df.empty:\n",
        "            resultado = df[coluna].dropna()\n",
        "        else:\n",
        "            resultado = self.base[coluna].dropna()\n",
        "        resultado = resultado.unique()\n",
        "        self.lstresultado = resultado.tolist()\n",
        "        if normalizar:\n",
        "            self.lstresultado = [self.normalize(x) for x in self.lstresultado]\n",
        "        return self.lstresultado\n",
        "      \n",
        "        \n",
        "    def check_similar(self, busca, porcentagem=50):\n",
        "        self.porcentagem = porcentagem\n",
        "        busca_normalizado = self.normalize(busca)\n",
        "        \n",
        "        self.resultado = {}\n",
        "        lst_porcentagens = []\n",
        "    \n",
        "        for Y in self.lstresultado:\n",
        "            #X = self.busca\n",
        "            X = busca_normalizado\n",
        "            \n",
        "            # tokenization \n",
        "            X_list = word_tokenize(X)  \n",
        "            Y_list = word_tokenize(Y)\n",
        "  \n",
        "            # sw contains the list of stopwords \n",
        "            sw = stopwords.words('portuguese')  \n",
        "            l1 =[];l2 =[] \n",
        "  \n",
        "            # remove stop words from the string \n",
        "            X_set = {w for w in X_list if not w in sw}  \n",
        "            Y_set = {w for w in Y_list if not w in sw}\n",
        "            \n",
        "  \n",
        "            # form a set containing keywords of both strings  \n",
        "            rvector = X_set.union(Y_set)  \n",
        "            for w in rvector: \n",
        "                if w in X_set: l1.append(1) # create a vector \n",
        "                else: l1.append(0) \n",
        "                if w in Y_set: l2.append(1) \n",
        "                else: l2.append(0) \n",
        "            c = 0\n",
        "  \n",
        "            # cosine formula  \n",
        "            for i in range(len(rvector)): \n",
        "                c+= l1[i]*l2[i] \n",
        "                cosine = c / float((sum(l1)*sum(l2))**0.5)\n",
        "            porcento = float(\"{:.3f}\".format(cosine))*100\n",
        "            \n",
        "            if round(porcento, 0) > self.porcentagem:\n",
        "                if round(porcento, 0) == 100:\n",
        "                    lst_porcentagens=[]\n",
        "                    return Y\n",
        "                    break\n",
        "                    \n",
        "                self.resultado.setdefault(round(porcento, 1), []).append(Y)\n",
        "                lst_porcentagens.append(round(porcento, 1))\n",
        "                \n",
        "        if len(self.resultado) == 1:\n",
        "            return self.resultado[lst_porcentagens[-1]][0]\n",
        "\n",
        "        if lst_porcentagens:\n",
        "            lst_porcentagens.sort()\n",
        "            return self.resultado\n",
        "\n",
        "class Core():\n",
        "\n",
        "    def __init__(self):\n",
        "        self.df_base = []\n",
        "\n",
        "    def files(self, path, extension):\n",
        "        for file in os.listdir(path):\n",
        "            if os.path.isfile(os.path.join(path, file)):\n",
        "                if re.search(extension, file):\n",
        "                    yield file\n",
        "\n",
        "    def dir_list(self, path=None, extension=None):\n",
        "        dir_list = []\n",
        "        for path_info in path:\n",
        "            dirs = self.files(path_info, extension)\n",
        "            for dir_info in dirs:\n",
        "                dir_list.append(\"%s/%s\" % (path_info, dir_info))\n",
        "        return dir_list\n",
        "\n",
        "    def read(self, input=None, ies=None, clean_cache=None, encode=None):\n",
        "        if clean_cache:\n",
        "            self.df_base = []\n",
        "\n",
        "        if encode:\n",
        "          encoding = encode\n",
        "        else:\n",
        "          encoding = 'iso-8859-1'\n",
        "\n",
        "        df = pd.read_csv(input, sep=\";\", encoding=encoding, low_memory=False)\n",
        "        \n",
        "        base_cols = df.columns.tolist()\n",
        "        for col in base_cols:\n",
        "            try:\n",
        "                df[col] = df[col].str.strip()\n",
        "            except Exception as e:\n",
        "                pass\n",
        "        self.df_base.append(df)\n",
        "\n",
        "    def join(self):\n",
        "        self.result = pd.concat(self.df_base, sort=False)\n",
        "        self.result = self.result.replace(np.nan, '', regex=True)\n",
        "\n",
        "    def export(self):\n",
        "        return self.result #.values.tolist()\n",
        "        #Output sem formatação\n",
        "        #with pd.ExcelWriter(f'PANDAS.xlsx') as writer:\n",
        "        #    self.result.to_excel(writer, sheet_name=sheet, index=False)\n"
      ],
      "metadata": {
        "id": "uN8k1MQdFTBK"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Limpando e criando a pasta para colocar os dicionários:"
      ],
      "metadata": {
        "id": "S7mOfbAmsmON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "print('Limpando arquivos antigos')\n",
        "try:\n",
        "  shutil.rmtree('arquivos')\n",
        "except Exception as e:\n",
        "  pass\n",
        "  #print(f'Erro: {e}')\n",
        "\n",
        "print('Criando a pasta \"arquivos\"')\n",
        "!mkdir arquivos"
      ],
      "metadata": {
        "id": "QfzxWH5nLjyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Informar o arquivo CSV com o dicionário que deseja utilizar (é possível escolher vários arquivos ao mesmo tempo):"
      ],
      "metadata": {
        "id": "g1zblVVwtRTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dicionário utilizado\n",
        "#http://blog.mds.gov.br/redesuas/lista-de-municipios-brasileiros/\n",
        "#Codificação ISO-8859-1\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "print('Escolha o arquivo CSV')\n",
        "ap_up = files.upload()\n",
        "!mv *.csv arquivos"
      ],
      "metadata": {
        "id": "LrD0sv_2FY8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora é só unificar todos os arquivos CSV que você fez upload, os arquivos que eu estou utilizando nesse exemplo estão com uma codificação \"ISO-8859-1\", porém é possível subir arquivos com qualquer codificação, deixei comentado no código um outro padrão que é bem comum na internet \"UTF-8\":"
      ],
      "metadata": {
        "id": "SCr88vnPtoNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from base64 import encode\n",
        "\n",
        "app = Core()\n",
        "acervo = check_similar()\n",
        "\n",
        "dir_list = app.dir_list(path=['arquivos'], extension='.csv$')\n",
        "\n",
        "#Primeiro vamos unir todos os dicionários\n",
        "if len(dir_list) > 0:\n",
        "  for csvfile in dir_list:\n",
        "    print(f'Trabalhando no arquivo {csvfile}')\n",
        "    #app.read(input=csvfile, encode='UTF-8')\n",
        "    app.read(input=csvfile, encode='ISO-8859-1')\n",
        "  app.join()\n",
        "  lista = app.export()"
      ],
      "metadata": {
        "id": "FoMv7lPGGYzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Informar na lista chamada \"busca\" as palavras que você deseja encontrar. No exemplo utilizado eu coloquei em uma frase completa com 2 municípios que estão na base CSV:"
      ],
      "metadata": {
        "id": "uVXflDJQu6tF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Informar a coluna que está a informação que você deseja pesquisar\n",
        "acervo.criar_lista(coluna='Município', df=lista)\n",
        "#Na busca, você pode colocar em formato de lista todas buscas que deseja buscar\n",
        "busca = ['Rio grande fica em qual estado?', 'Pontos turísticos de Boa Vista']\n",
        "\n",
        "for nome in busca:\n",
        "  #Retornar apenas valores com similaridade maior que 50%\n",
        "  resultado = acervo.check_similar(busca=nome, porcentagem=50)\n",
        "  if isinstance(resultado, dict):\n",
        "    #Se retornar uma lista com mais de 1 resultado, mostrar valor em linhas\n",
        "    for porcentagem in resultado:\n",
        "       for valor in resultado[porcentagem]:\n",
        "         print(f'{porcentagem}%: {valor}')\n",
        "  elif resultado is None:\n",
        "    #Se retornar \"nada\", informar que não encontrou nada\n",
        "    print(f'0%: Não encontrado')\n",
        "  else:\n",
        "    #Se retornar um único valor, significar que foi um resultado 100%\n",
        "    print(f'100%: {resultado}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBpZCYkfcnpI",
        "outputId": "52ef65c0-b7c8-4675-f0f3-9a378cddc23a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%: RIO GRANDE\n",
            "63.2%: BOA VISTA\n",
            "51.6%: NOVA BOA VISTA\n",
            "51.6%: ALTO BOA VISTA\n"
          ]
        }
      ]
    }
  ]
}